{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vjoshy/NNFS/blob/main/pyTorch_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhvTZOBrPl0l"
      },
      "source": [
        "#  PyTorch Tutorial\n",
        "\n",
        "This is the code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngH43bYeRnIU",
        "outputId": "89a47ecf-f0df-4a57-af93-ea76a5619aae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hLMP1Tp3Pl0m",
        "outputId": "e9be0cde-867f-4a1f-a292-22aa627c696e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a2e90005619f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "data = np.array(pd.read_csv('train.csv'))\n",
        "print(data.shape)\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "m, n = data.shape\n",
        "\n",
        "# training split\n",
        "test = data[0:5000].T\n",
        "y_test = test[0]\n",
        "x_test = (test[1:n])/255\n",
        "\n",
        "# test split\n",
        "train = data[5000:m].T\n",
        "y_train = train[0]\n",
        "x_train = (train[1:n])/255\n",
        "\n",
        "print(test.shape)\n",
        "print(train.shape)\n",
        "\n",
        "print(x_train[:, 420].shape)\n",
        "\n",
        "# Display image\n",
        "plt.imshow(x_train[:, 420].reshape(28, 28), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KfDi9kbPl0m"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# Prepare data\n",
        "x_train_tensor = torch.FloatTensor(x_train.T).to(device)  # Shape: [32000, 784]\n",
        "y_train_tensor = torch.LongTensor(y_train.astype(int)).to(device)  #  [32000]\n",
        "\n",
        "x_test_tensor = torch.FloatTensor(x_test.T).to(device)  #  [5000, 784]\n",
        "y_test_tensor = torch.LongTensor(y_test.astype(int)).to(device) # [784]\n",
        "\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "# Create network function\n",
        "def create_network(input_size, hidden_size, output_size):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size), nn.ReLU(),\n",
        "        nn.Linear(hidden_size, hidden_size), nn.ReLU(),\n",
        "        nn.Linear(hidden_size, output_size)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPMQG6evPl0n"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define network parameters\n",
        "input_size = 784\n",
        "hidden_size = 16\n",
        "output_size = 10 # classification problem ergo: 0 - 9 digits to classify\n",
        "\n",
        "# Create the network\n",
        "BalkaNet = create_network(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(BalkaNet.parameters(), lr=0.001)# Adaptive momentum optimizer - like SGD but better\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "episodes = 101\n",
        "for ep in tqdm(range(episodes)):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        # outputs  from network - \"logits\"\n",
        "        outputs = BalkaNet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # zeroing gradient from previously to prevent gradient accumulation\n",
        "        # back propagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # tracking total losses from each episode\n",
        "    loss_history.append(running_loss)\n",
        "    if ep % 50 == 0:\n",
        "        print(f\"Episode {ep}, Loss: {running_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# evaluation\n",
        "BalkaNet.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = BalkaNet(x_test_tensor)\n",
        "    test_logits, test_predicted = torch.max(test_outputs, 1)\n",
        "\n",
        "    test_correct = (test_predicted == y_test_tensor).sum().item()\n",
        "    test_accuracy = test_correct / y_test_tensor.size(0)\n",
        "\n",
        "print(f\"test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Plot the loss history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_history)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOHvgsPVPl0n"
      },
      "source": [
        "## A note about logits\n",
        "\n",
        "The raw values from the final layer are called \"logits\" by convention in machine learning and neural networks. These values are essentially the weighted sum of inputs to that final layer, calculated by the linear transformation (matrix multiplication plus bias): `z = Wx + b`.\n",
        "\n",
        "The term \"logit\" comes from logistic regression, where the log-odds ratio is often called the logit, where `logit(p) = log(p/(1-p))`. Maps `(0,1)` of probability to `(-inf, inf)`. To go back to p, we'd use something like a sigmoid function i.e, `sigmoid(z) = 1/(1+e^(-z))`, where z is the \"logit\".\n",
        "\n",
        "In neural networks, this term has been adopted more broadly to refer to the raw, unnormalized outputs of the network before any final activation function like softmax is applied. There's nothing special about these values that inherently makes them \"logits\" - they're simply the direct outputs of the final linear layer. We call them logits because they serve the same function as logits in logistic regression: they represent unnormalized scores that, after transformation (typically through softmax), can be interpreted as probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XSXt_RgPl0o"
      },
      "outputs": [],
      "source": [
        "index = 5\n",
        "\n",
        "for index in range(5):\n",
        "    BalkaNet.eval()\n",
        "    with torch.no_grad():\n",
        "        img = x_test_tensor[index:index+1]\n",
        "        output = BalkaNet(img)\n",
        "        max_logit, predicted_img = torch.max(output, 1)\n",
        "\n",
        "    print(f\"Prediction: {predicted_img.item()}\")\n",
        "    print(f\"Actual: {y_test_tensor[index].item()}\")\n",
        "\n",
        "    # Display image\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    plt.imshow(x_test_tensor[index].cpu().numpy().reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Pred: {predicted_img.item()} | True: {y_test_tensor[index].item()}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnC7dG4-Pl0o"
      },
      "source": [
        "The following code is to convert any image into MNIST format. Ensure cv2 library is installed, if not it can b installed via  `pip install opencv-python`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVBpC7KcPl0o"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def preprocess_digit(image_path, target_size=(28, 28)):\n",
        "\n",
        "    # Read the image and convert to grayscale\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image {image_path}\")\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image - Otsu works well for clear handwriting on white paper\n",
        "    b, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Find contours to identify the digit\n",
        "    contours, d = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # If contours exist, find the largest one (should be the digit)\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "        # Add some padding\n",
        "        padding = 4\n",
        "        x_start = max(0, x - padding)\n",
        "        y_start = max(0, y - padding)\n",
        "        x_end = min(binary.shape[1], x + w + padding)\n",
        "        y_end = min(binary.shape[0], y + h + padding)\n",
        "\n",
        "        # Extract the digit\n",
        "        digit = binary[y_start:y_end, x_start:x_end]\n",
        "    else:\n",
        "        # If no contours found, use the whole image\n",
        "        digit = binary\n",
        "\n",
        "    # Make square by padding\n",
        "    h, w = digit.shape\n",
        "    if h > w:\n",
        "        diff = h - w\n",
        "        pad_left = diff // 2\n",
        "        pad_right = diff - pad_left\n",
        "        digit = cv2.copyMakeBorder(digit, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value=0)\n",
        "    else:\n",
        "        diff = w - h\n",
        "        pad_top = diff // 2\n",
        "        pad_bottom = diff - pad_top\n",
        "        digit = cv2.copyMakeBorder(digit, pad_top, pad_bottom, 0, 0, cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "    # Resize to target size\n",
        "    digit = cv2.resize(digit, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    mnist_img = digit / 255.0\n",
        "\n",
        "    # Create PyTorch tensor and add batch dimension\n",
        "    tensor_img = torch.FloatTensor(mnist_img).unsqueeze(0)\n",
        "\n",
        "    # Flatten the tensor to match model input shape (if needed)\n",
        "    if len(tensor_img.shape) == 3:  # [batch, height, width]\n",
        "        tensor_img = tensor_img.reshape(1, -1)  # Flatten to [batch, 784]\n",
        "\n",
        "    return mnist_img, tensor_img\n",
        "\n",
        "# Example usage with visualization\n",
        "def test_digit_preprocessing(image_path):\n",
        "\n",
        "    # Preprocess the digit\n",
        "    mnist_img, tensor_img = preprocess_digit(image_path)\n",
        "\n",
        "    # Display original image\n",
        "    orig_img = cv2.imread(image_path)\n",
        "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    # Show original image\n",
        "    ax1.imshow(orig_img)\n",
        "    ax1.set_title(\"Original Image\")\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Show processed image\n",
        "    ax2.imshow(mnist_img, cmap='gray')\n",
        "    ax2.set_title(\"Processed Image (MNIST format)\")\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Tensor shape: {tensor_img.shape}\")\n",
        "\n",
        "    return mnist_img, tensor_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ04F9kXPl0p"
      },
      "source": [
        "## Testing our trained neural network on handwriting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe0jvGvIPl0p"
      },
      "outputs": [],
      "source": [
        "# load and preprocess custom image\n",
        "\n",
        "#mnist_img, tensor_img = preprocess_digit(\"digits/zero.jpg\")\n",
        "\n",
        "mnist_img, tensor_img = test_digit_preprocessing(\"/content/drive/MyDrive/School/2025/Winter 2025/NN Workshop/Tutorial/digits/zero.jpg\")\n",
        "\n",
        "\n",
        "# make a prediction\n",
        "BalkaNet.eval()\n",
        "with torch.no_grad():\n",
        "    output = BalkaNet(tensor_img.to(device))\n",
        "    data, predicted = torch.max(output, 1)\n",
        "\n",
        "# display result\n",
        "print(f\"Prediction: {predicted.item()}\")\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(mnist_img, cmap='gray')\n",
        "plt.title(f\"Prediction: {predicted.item()}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}